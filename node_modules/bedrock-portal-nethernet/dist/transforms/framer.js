"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.Framer = exports.CompressionAlgorithm = void 0;
const [readVarInt, writeVarInt, sizeOfVarInt] = require('protodef').types.varint;
const zlib_1 = __importDefault(require("zlib"));
var CompressionAlgorithm;
(function (CompressionAlgorithm) {
    CompressionAlgorithm["None"] = "none";
    CompressionAlgorithm["Deflate"] = "deflate";
    CompressionAlgorithm["Snappy"] = "snappy";
})(CompressionAlgorithm || (exports.CompressionAlgorithm = CompressionAlgorithm = {}));
// Concatenates packets into one batch packet, and adds length prefixs.
class Framer {
    packets;
    batchHeader;
    compressor;
    compressionLevel;
    compressionThreshold;
    compressionHeader;
    writeCompressor;
    constructor(client) {
        this.packets = [];
        this.batchHeader = client.batchHeader;
        this.compressor = client.compressionAlgorithm || 'none';
        this.compressionLevel = client.compressionLevel;
        this.compressionThreshold = client.compressionThreshold;
        this.compressionHeader = client.compressionHeader || 0;
        this.writeCompressor = client.compressionReady;
    }
    // No compression in base class
    compress(buffer) {
        switch (this.compressor) {
            case CompressionAlgorithm.Deflate: return zlib_1.default.deflateRawSync(buffer, { level: this.compressionLevel });
            case CompressionAlgorithm.Snappy: throw Error('Snappy compression not implemented');
            case CompressionAlgorithm.None: return buffer;
        }
    }
    static decompress(algorithm, buffer) {
        switch (algorithm) {
            case 0:
            case 'deflate':
                return zlib_1.default.inflateRawSync(buffer, { chunkSize: 512000 });
            case 1:
            case 'snappy':
                throw Error('Snappy compression not implemented');
            case 'none':
            case 255:
                return buffer;
            default: throw Error('Unknown compression type ' + algorithm);
        }
    }
    static decode(client, buf) {
        const headerLength = client.batchHeader.length;
        if (buf.length < headerLength) {
            throw new Error('Unexpected EOF');
        }
        const buffer = buf.slice(headerLength);
        let decompressed;
        if (client.compressionReady) {
            decompressed = this.decompress(buffer[0], buffer.slice(1));
        }
        else {
            // On old versions, compressor is session-wide ; failing to decompress
            // a packet will assume it's not compressed
            try {
                decompressed = this.decompress(client.compressionAlgorithm, buffer);
            }
            catch (e) {
                decompressed = buffer;
            }
        }
        return Framer.getPackets(decompressed);
    }
    encode() {
        const buf = Buffer.concat(this.packets);
        const shouldCompress = (buf.length > this.compressionThreshold);
        const compressed = shouldCompress ? this.compress(buf) : buf;
        const header = this.writeCompressor ? [...this.batchHeader, shouldCompress ? this.compressionHeader : 255] : this.batchHeader;
        return Buffer.concat([Buffer.from(header), compressed]);
    }
    addEncodedPacket(chunk) {
        const varIntSize = sizeOfVarInt(chunk.byteLength);
        const buffer = Buffer.allocUnsafe(varIntSize + chunk.byteLength);
        writeVarInt(chunk.length, buffer, 0);
        chunk.copy(buffer, varIntSize);
        this.packets.push(buffer);
    }
    addEncodedPackets(packets) {
        let allocSize = 0;
        for (const packet of packets) {
            allocSize += sizeOfVarInt(packet.byteLength);
            allocSize += packet.byteLength;
        }
        const buffer = Buffer.allocUnsafe(allocSize);
        let offset = 0;
        for (const chunk of packets) {
            offset = writeVarInt(chunk.length, buffer, offset);
            offset += chunk.copy(buffer, offset, 0);
        }
        this.packets.push(buffer);
    }
    getBuffer() {
        return Buffer.concat(this.packets);
    }
    static getPackets(buffer) {
        const packets = [];
        let offset = 0;
        while (offset < buffer.byteLength) {
            const { value, size } = readVarInt(buffer, offset);
            const dec = Buffer.allocUnsafe(value);
            offset += size;
            offset += buffer.copy(dec, 0, offset, offset + value);
            packets.push(dec);
        }
        return packets;
    }
}
exports.Framer = Framer;
